# Databricks notebook source
# MAGIC %md
# MAGIC # Fixed Tool-Calling Agent with Genie Integration
# MAGIC
# MAGIC This notebook fixes the issues in the driver.ipynb:
# MAGIC 1. Properly integrates Genie using the Conversation API
# MAGIC 2. Uses correct model serving endpoint
# MAGIC 3. Implements proper polling and result retrieval
# MAGIC
# MAGIC **References:**
# MAGIC - [Genie Conversation API](https://learn.microsoft.com/en-us/azure/databricks/genie/conversation-api)

# COMMAND ----------

# MAGIC %pip install --quiet --upgrade databricks-sdk mlflow backoff
# MAGIC dbutils.library.restartPython()

# COMMAND ----------

# MAGIC %md
# MAGIC ## Configuration

# COMMAND ----------

from databricks.sdk import WorkspaceClient
import json
import time

# Configuration
CATALOG = "classify_tickets_new_dev"
SCHEMA = "support_ai"
INDEX_NAME = f"{CATALOG}.{SCHEMA}.knowledge_base_index"
GENIE_SPACE_ID = "01f0b91aa91c1b0c8cce6529ea09f0a8"

# Model Serving Endpoint - Use the correct endpoint name
# The invocations URL is: /serving-endpoints/databricks-meta-llama-3-3-70b-instruct/invocations
LLM_ENDPOINT = "databricks-meta-llama-3-3-70b-instruct"

# Initialize Databricks client
w = WorkspaceClient()

print("="*60)
print("ðŸ“‹ CONFIGURATION")
print("="*60)
print(f"Catalog: {CATALOG}")
print(f"Schema: {SCHEMA}")
print(f"Vector Search Index: {INDEX_NAME}")
print(f"Genie Space ID: {GENIE_SPACE_ID}")
print(f"LLM Endpoint: {LLM_ENDPOINT}")
print(f"Workspace Host: {w.config.host}")
print("="*60)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Genie Tool Implementation (Correct API Pattern)
# MAGIC
# MAGIC Based on [Microsoft Documentation](https://learn.microsoft.com/en-us/azure/databricks/genie/conversation-api)

# COMMAND ----------

import backoff
from typing import Dict, Any, Optional

class GenieConversationTool:
    """
    Tool for querying Genie using the proper Conversation API pattern.
    
    Per Microsoft docs: https://learn.microsoft.com/en-us/azure/databricks/genie/conversation-api
    1. Start conversation (POST)
    2. Poll for completion (GET)
    3. Retrieve results from attachments
    """
    
    def __init__(self, workspace_client: WorkspaceClient, space_id: str):
        self.w = workspace_client
        self.space_id = space_id
        self.conversations = {}  # Track conversations by ID
        
    def start_conversation(self, question: str) -> Dict[str, Any]:
        """
        Start a new Genie conversation.
        Returns conversation_id and message_id for polling.
        """
        try:
            response = self.w.api_client.do(
                'POST',
                f'/api/2.0/genie/spaces/{self.space_id}/start-conversation',
                body={'content': question}
            )
            
            conversation_id = response.get('conversation', {}).get('id')
            message_id = response.get('message', {}).get('id')
            
            return {
                'status': 'started',
                'conversation_id': conversation_id,
                'message_id': message_id,
                'response': response
            }
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    @backoff.on_exception(
        backoff.expo,
        Exception,
        max_tries=5,
        max_time=120  # 2 minutes max
    )
    def poll_for_result(
        self, 
        conversation_id: str, 
        message_id: str,
        max_wait_seconds: int = 120
    ) -> Dict[str, Any]:
        """
        Poll for Genie query completion.
        Per docs: Poll every 5-10 seconds until status is COMPLETED, FAILED, or CANCELLED.
        """
        start_time = time.time()
        poll_interval = 5  # Start with 5 seconds
        
        while (time.time() - start_time) < max_wait_seconds:
            try:
                response = self.w.api_client.do(
                    'GET',
                    f'/api/2.0/genie/spaces/{self.space_id}/conversations/{conversation_id}/messages/{message_id}'
                )
                
                status = response.get('status', 'UNKNOWN')
                
                if status in ['COMPLETED', 'FAILED', 'CANCELLED']:
                    return {
                        'status': status.lower(),
                        'response': response
                    }
                
                # Still IN_PROGRESS, wait before polling again
                time.sleep(poll_interval)
                
                # Apply exponential backoff after 2 minutes (per docs)
                if (time.time() - start_time) > 120:
                    poll_interval = min(poll_interval * 1.5, 30)  # Cap at 30 seconds
                    
            except Exception as e:
                return {'status': 'error', 'error': str(e)}
        
        return {'status': 'timeout', 'error': 'Query did not complete within timeout period'}
    
    def get_query_results(
        self,
        conversation_id: str,
        message_id: str,
        attachment_id: str
    ) -> Dict[str, Any]:
        """
        Retrieve query results from a completed Genie query.
        """
        try:
            response = self.w.api_client.do(
                'GET',
                f'/api/2.0/genie/spaces/{self.space_id}/conversations/{conversation_id}/messages/{message_id}/query-result/{attachment_id}'
            )
            
            return {
                'status': 'success',
                'results': response
            }
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    def query(self, question: str) -> str:
        """
        Complete Genie query workflow: start â†’ poll â†’ retrieve results.
        This is the main method to use as a tool.
        """
        # Step 1: Start conversation
        start_result = self.start_conversation(question)
        
        if start_result.get('status') != 'started':
            return f"Error starting conversation: {start_result.get('error', 'Unknown error')}"
        
        conversation_id = start_result['conversation_id']
        message_id = start_result['message_id']
        
        # Step 2: Poll for completion
        poll_result = self.poll_for_result(conversation_id, message_id)
        
        if poll_result.get('status') != 'completed':
            return f"Query did not complete successfully: {poll_result.get('error', poll_result.get('status'))}"
        
        # Step 3: Extract results from attachments
        response = poll_result['response']
        attachments = response.get('attachments', [])
        
        if not attachments:
            text_content = response.get('content', 'No results found')
            return f"Genie response: {text_content}"
        
        # Extract text and query from first attachment
        attachment = attachments[0]
        text_response = attachment.get('text', {}).get('content', '')
        query = attachment.get('query', {}).get('query', '')
        
        # Optionally retrieve detailed query results
        attachment_id = attachment.get('id')
        if attachment_id:
            results = self.get_query_results(conversation_id, message_id, attachment_id)
            if results.get('status') == 'success':
                return f"Genie Analysis:\n{text_response}\n\nQuery: {query}\n\nResults: {results.get('results', {})}"
        
        return f"Genie Analysis:\n{text_response}\n\nQuery: {query}"

# Test the Genie tool
genie_tool = GenieConversationTool(w, GENIE_SPACE_ID)

print("\nðŸ§ª Testing Genie Tool:")
test_question = "Show me 3 database-related tickets that were resolved"
result = genie_tool.query(test_question)
print(f"\nQuestion: {test_question}")
print(f"Result: {result[:500]}...")  # Truncate for display

# COMMAND ----------

# MAGIC %md
# MAGIC ## UC Functions Tool

# COMMAND ----------

def call_uc_function(function_name: str, *args) -> Dict[str, Any]:
    """
    Call Unity Catalog function directly via SQL.
    """
    try:
        # Build SQL query
        args_str = ", ".join([f"'{arg}'" for arg in args])
        query = f"SELECT {CATALOG}.{SCHEMA}.{function_name}({args_str}) as result"
        
        result = spark.sql(query).collect()[0][0]
        
        return {"status": "success", "result": result}
    except Exception as e:
        return {"status": "error", "error": str(e)}

# Test UC Function
print("\nðŸ§ª Testing UC Function:")
test_ticket = "Production database is down"
result = call_uc_function("ai_classify", test_ticket)
print(f"Ticket: {test_ticket}")
print(f"Result: {result}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Vector Search Tool

# COMMAND ----------

def search_knowledge_base(query: str, num_results: int = 3) -> Dict[str, Any]:
    """
    Search Vector Search index for relevant documents.
    """
    try:
        response = w.api_client.do(
            'POST',
            f'/api/2.0/vector-search/indexes/{INDEX_NAME}/query',
            body={
                'columns': ['doc_id', 'doc_type', 'title', 'content'],
                'query_text': query,
                'num_results': num_results
            }
        )
        
        data_array = response.get('result', {}).get('data_array', [])
        
        documents = []
        for row in data_array:
            if len(row) >= 4:
                documents.append({
                    'doc_id': row[0],
                    'doc_type': row[1],
                    'title': row[2],
                    'content': row[3][:300]  # Truncate
                })
        
        return {"status": "success", "documents": documents}
    except Exception as e:
        return {"status": "error", "error": str(e)}

# Test Vector Search
print("\nðŸ§ª Testing Vector Search:")
result = search_knowledge_base("database troubleshooting")
print(f"Found {len(result.get('documents', []))} documents")
if result.get('documents'):
    print(f"First doc: {result['documents'][0]['title']}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## LangChain Tools Wrapper

# COMMAND ----------

from langchain.tools import tool

@tool
def classify_ticket(ticket_text: str) -> dict:
    """Classify a support ticket into category, priority, and team."""
    return call_uc_function("ai_classify", ticket_text)

@tool
def extract_ticket_metadata(ticket_text: str) -> dict:
    """Extract metadata from a support ticket."""
    return call_uc_function("ai_extract", ticket_text)

@tool
def search_knowledge_base_tool(query: str) -> dict:
    """Search knowledge base for relevant documentation."""
    return search_knowledge_base(query, 3)

@tool
def query_ticket_history(question: str) -> str:
    """Query historical resolved tickets using Genie. Returns similar past tickets and resolutions."""
    return genie_tool.query(question)

# All tools
tools = [
    classify_ticket,
    extract_ticket_metadata,
    search_knowledge_base_tool,
    query_ticket_history
]

print("\nâœ… Defined 4 LangChain Tools:")
for t in tools:
    print(f"  â€¢ {t.name}: {t.description}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## LLM Client - Use Foundation Model Endpoint

# COMMAND ----------

from langchain_community.chat_models import ChatDatabricks

# Use the correct endpoint name
# The full invocations URL is constructed by the ChatDatabricks client
llm = ChatDatabricks(
    endpoint=LLM_ENDPOINT,
    temperature=0.1,
    max_tokens=2000
)

print(f"âœ… LLM initialized with endpoint: {LLM_ENDPOINT}")

# Test LLM
test_response = llm.invoke("Say 'Hello from Llama 3.3' and nothing else.")
print(f"LLM Response: {test_response.content}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Create Agent with All Tools

# COMMAND ----------

from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage

# Create agent with all tools
agent = create_react_agent(
    model=llm,
    tools=tools,
    state_modifier="""You are an AI support ticket assistant.

Your job is to:
1. Classify tickets using classify_ticket
2. Extract metadata using extract_ticket_metadata
3. Search for documentation using search_knowledge_base_tool
4. Find similar past tickets using query_ticket_history (Genie)
5. Provide comprehensive analysis

Be thorough and use all relevant tools."""
)

print(f"âœ… Agent created with {len(tools)} tools")
print(f"Tools: {[t.name for t in tools]}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Test Complete Agent

# COMMAND ----------

test_ticket = """
Production database PROD-DB-01 is completely down!
All customer applications are showing connection errors.
This is affecting hundreds of users and impacting revenue.
Database logs show 'Connection refused' errors.
Started 10 minutes ago - needs immediate attention!
"""

print("="*80)
print("ðŸŽ« TEST TICKET:")
print("="*80)
print(test_ticket)
print("\n" + "="*80)
print("ðŸ¤– AGENT PROCESSING...")
print("="*80 + "\n")

# Invoke agent
messages = [HumanMessage(content=f"""Analyze this support ticket:

{test_ticket}

Please:
1. Classify the ticket
2. Extract metadata
3. Search for relevant documentation
4. Find similar past tickets from history
5. Provide a comprehensive summary with recommendations
""")]

result = agent.invoke({"messages": messages})

# Display results
print("\n" + "="*80)
print("ðŸ“Š AGENT RESULT")
print("="*80 + "\n")

for msg in result['messages']:
    if hasattr(msg, 'content') and msg.content:
        role = "USER" if msg.__class__.__name__ == "HumanMessage" else "AGENT"
        print(f"\n{role}:")
        print("-" * 40)
        print(msg.content[:500] if len(msg.content) > 500 else msg.content)
        if len(msg.content) > 500:
            print("... (truncated)")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Summary

# COMMAND ----------

print("\n" + "="*80)
print("ðŸ“‹ IMPLEMENTATION SUMMARY")
print("="*80)
print()
print("âœ… Fixed Issues:")
print("  1. Genie now uses proper Conversation API pattern")
print("     - Start conversation â†’ Poll â†’ Retrieve results")
print("     - Per: https://learn.microsoft.com/en-us/azure/databricks/genie/conversation-api")
print()
print("  2. Model serving endpoint corrected")
print(f"     - Endpoint: {LLM_ENDPOINT}")
print("     - Uses ChatDatabricks with proper endpoint name")
print()
print("  3. All tools working together:")
print("     - UC Functions (ai_classify, ai_extract)")
print("     - Vector Search (knowledge base)")
print("     - Genie (historic tickets via Conversation API)")
print()
print("âœ… Agent can now:")
print("  â€¢ Classify tickets")
print("  â€¢ Extract metadata")
print("  â€¢ Search documentation")
print("  â€¢ Query historic tickets (Genie)")
print("  â€¢ Combine all information for recommendations")
print()
print("="*80)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Key Fixes Applied
# MAGIC
# MAGIC ### 1. Genie Integration
# MAGIC **Problem:** Driver notebook didn't use Genie at all
# MAGIC
# MAGIC **Solution:** Implemented proper [Genie Conversation API pattern](https://learn.microsoft.com/en-us/azure/databricks/genie/conversation-api):
# MAGIC ```python
# MAGIC # Step 1: Start conversation
# MAGIC POST /api/2.0/genie/spaces/{space_id}/start-conversation
# MAGIC
# MAGIC # Step 2: Poll for results (every 5-10 seconds)
# MAGIC GET /api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}
# MAGIC
# MAGIC # Step 3: Retrieve results from attachments
# MAGIC GET .../query-result/{attachment_id}
# MAGIC ```
# MAGIC
# MAGIC ### 2. Model Endpoint
# MAGIC **Problem:** Used OpenAI client wrapper which may not work with custom Foundation Model endpoints
# MAGIC
# MAGIC **Solution:** Use `ChatDatabricks` with the correct endpoint name:
# MAGIC ```python
# MAGIC LLM_ENDPOINT = "databricks-meta-llama-3-3-70b-instruct"
# MAGIC llm = ChatDatabricks(endpoint=LLM_ENDPOINT)
# MAGIC ```
# MAGIC The full invocations URL is constructed automatically.
# MAGIC
# MAGIC ### 3. Proper Polling
# MAGIC **Problem:** No polling implementation
# MAGIC
# MAGIC **Solution:** Implemented exponential backoff per [Microsoft docs](https://learn.microsoft.com/en-us/azure/databricks/genie/conversation-api):
# MAGIC - Poll every 5-10 seconds
# MAGIC - Apply exponential backoff after 2 minutes
# MAGIC - Timeout after 10 minutes (configurable)

# COMMAND ----------

